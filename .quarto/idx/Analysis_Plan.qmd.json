{"title":"Analysis Plan","markdown":{"yaml":{"title":"Analysis Plan","format":{"html":{"self-contained":true,"code-line-numbers":true},"pdf":{"documentclass":"article"}},"custom_title_page":false,"filters":["lightbox"],"lightbox":"auto"},"headingText":"  title-block-author-single: \"Writer\"","containsRefs":false,"markdown":"\n\n---\nsubtitle: \"Planing the data cleaning and data analysis\"\ndate: 2023-02-27\n\nauthor:\n  - name: Javier Silva-Valencia\n    orcid: 0000-0002-5982-2821\n    email: javier.silva@unmsm.edu.pe\n    affiliations:\n      - name: Instituut Voor Tropische Geneeskunde. Antwerp-Belgium\n\nlanguage: \n\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\n\n## Data Cleaning Plan\n\nThe aim of data cleaning is to create a single data set with all the variables of importance. This involves checking the NA values, creating an asset index (using the consumer goods variables), reshaping some data to work on the same unit, and merging all data sets. Let's go step by step:\n\n### 1. Reshape Q1_B_1 \nThis contains data of animals in household. We will reshape it so that each row should be a Household. We do that in order to merge with other datasets. Replace values if need it. (NA, -1)\n\n```{mermaid}\n%%| fig-width: 3.5\nflowchart LR\n  A[Q1_B_1] -->|reshape| B(New dataset:animals)\n```\n\n### 2. Create an asset index\nThis index should include information of consumer goods, as well if having a bovine animal and if having a brick wall household.\n\n#### 2.1. Select consumer goods\nSelect the consumer goods (from Q1_B_106 dataset) that will conform the asset.\n```{mermaid}\nflowchart LR\n  A[Q1_B_1] -->|transform to <br> dichotomous variables| B(New dataset:<br> assets)\n  B(New dataset:<br> assets) -->|only goods with prevalenc <br> between 5-95%| C(New dataset:<br> assets2)\n```\n\n#### 2.2. Create own_bovine variable \nUse the previously created \"animals\" dataset to create a variable of owning a bovine animal.\n```{mermaid}\nflowchart LR\n  A[animals] -->|subset <br> bovine animals| B(New dataset:<br> hlp1)\n```\n#### 2.3. Create brickwall variable\nUse the Q1_B dataset to create a variable if the household have brickwalls.\n```{mermaid}\nflowchart LR\n  A[Q1_B] -->|subset <br> brickwall variable| B(New dataset:<br> hlp2)\n```\n#### 2.4. Merging datasets \nMerge all this datasets in order to create the asset index\n```{mermaid}\nflowchart LR\n  A[hlp1] --> B(New dataset:<br> hlp)\n  C[hlp2] --> B(New dataset:<br> hlp)\n  B[New dataset:<br> hlp] --> D(New dataset:<br> assets3)\n  E[assets2] --> D(New dataset:<br> assets3)\n```\n#### 2.5. Use PCA to create asset_index \nCreate the asset index using the Principle component analysis (PCA) and then categorize it in 5 quintiles of wealth.\n```{mermaid}\nflowchart LR\n  A[New dataset:<br> assets3] -->|Principle component <br> analysis| B(New dataset:<br> assets4)\n```\n\n\n### 3. Merging all the databases\n\n#### 3.1. Final Merging \n(Questionnaire_1 + asset index + animals + Q1_B + Q1_Screening)\n\n```{mermaid}\nflowchart LR\n  A[Questionnaire_1] --> B(Quest1_assets4)\n  C(assets4) --> B(Quest1_assets4)\n  B(Quest1_assets4) --> D(Quest1_assets4_animals)\n  E(animals) --> D(Quest1_assets4_animals)\n  D(Quest1_assets4_animals) --> F(Quest1_assets4_animals_q1B)\n  G(Q1_B) --> F(Quest1_assets4_animals_q1B)\n  F(Quest1_assets4_animals_q1B)--> H(Quest1_assets4_animals_q1B_Persons)\n  I(Q1_Screening)--> H(Quest1_assets4_animals_q1B_Persons)\n```\n\n#### 3.2. Select variables of interest\nFor the final dataset\n```{mermaid}\nflowchart LR\n  A(Quest1_assets4_animals_q1B_Persons) -->|selecting variables <br> of interes| B(final_dataset)\n```\n\n::: callout-tip\nIn this final_dataset each row is a person.\n:::\n\n\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\n\n## Data Analysis Plan\n\n### 1. Exploring new variables\nExplore variables of importance as Mushahar caste, number of people living in each household, Having at least a bednet per three person, having thatched wall, unplastered brick wall or plastered brick wall, having damp_floor or spray their household.\n\n### 2. Univariate logistic regressions\nFor each of the factors recorded we assessed associations with VL in univariate logistic regression models, calculating odds ratios.\n\n### 3. Multivariate regression\nAny association that was found to be statistically significant at the level of α=0.10 in univariate analysis was assessed as a potential confounder in the association between bed net use and VL in bivariate analysis.\n\nWe then included in a multivariate model all  factors significant at the level of α=0.10 in the univariate models. \n\n### 4. Removing variables\nWe removed one at a time secondary exposures that did not significantly improve precision of the model. \n\n### 5. Check for interaction\nWith the variables retained, we checked for interactions, for this purpose categorical variables with more than two levels should be recoded to binary.\n\n\n\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":true,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":4,"reference-location":"margin","filters":["lightbox"],"self-contained":true,"output-file":"Analysis_Plan.html"},"language":{"title-block-author-single":"Writer"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","editor":"visual","knitr":{"opts_chunk":{"cache":true,"cache.lazy":false,"R.options":{"knitr.graphics.auto_pdf":true},"attr.source":".numberLines"}},"theme":{"light":["flatly","custom.scss"]},"fontsize":"16px","linestretch":1.6,"smooth-scroll":true,"title":"Analysis Plan","custom_title_page":false,"lightbox":"auto","subtitle":"Planing the data cleaning and data analysis","date":"2023-02-27","author":[{"name":"Javier Silva-Valencia","orcid":"0000-0002-5982-2821","email":"javier.silva@unmsm.edu.pe","affiliations":[{"name":"Instituut Voor Tropische Geneeskunde. Antwerp-Belgium"}]}]},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","filters":["lightbox"],"output-file":"Analysis_Plan.pdf"},"language":{"title-block-author-single":"Writer"},"metadata":{"block-headings":true,"editor":"visual","knitr":{"opts_chunk":{"cache":true,"cache.lazy":false,"R.options":{"knitr.graphics.auto_pdf":true},"attr.source":".numberLines"}},"title":"Analysis Plan","custom_title_page":false,"lightbox":"auto","subtitle":"Planing the data cleaning and data analysis","date":"2023-02-27","author":[{"name":"Javier Silva-Valencia","orcid":"0000-0002-5982-2821","email":"javier.silva@unmsm.edu.pe","affiliations":[{"name":"Instituut Voor Tropische Geneeskunde. Antwerp-Belgium"}]}],"documentclass":"article"},"extensions":{"book":{}}}}}